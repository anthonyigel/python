{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "### Author: Anthony Igel                       ###\n",
    "### Team: Category Management Transformation   ###\n",
    "### Project: Developing practical Python Tools ###\n",
    "### Purpose: Decision Tree                     ###\n",
    "### Date: 05/24/2018                           ###\n",
    "##################################################\n",
    "\n",
    "# https://medium.com/@haydar_ai/learning-data-science-day-21-decision-tree-on-iris-dataset-267f3219a7fa\n",
    "    \n",
    "######################################################################\n",
    "########                     Import Modules                   ########\n",
    "######################################################################\n",
    "import py_effo as py_effo\n",
    "\n",
    "### pandas\n",
    "# Pandas is for structured data operations and manipulations, extensively used for data preparation\n",
    "import pandas as pd\n",
    "\n",
    "### numpy\n",
    "# NumPy stands for Numerical Python, a library contains basic linear algebra functions, Fourier Transforms and advanced random\n",
    "# number capabilities\n",
    "import numpy as np \n",
    "\n",
    "### Scipy\n",
    "# Scipy performs a host of statistical calculations, built on top of Numpy, thus we do not need to import Numpy as all Numpy\n",
    "# functions are contained in Scipy\n",
    "# https://oneau.wordpress.com/2011/02/28/simple-statistics-with-scipy/\n",
    "import scipy as sp\n",
    "\n",
    "### sklearn\n",
    "# Sklearn contains basic statistical models\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# As well as a module to calculate model performance statistics\n",
    "from sklearn import metrics, model_selection, tree\n",
    "\n",
    "### Statsmodels\n",
    "# Sklearn contains basic statistical models and data sets\n",
    "import statsmodels.api as sm\n",
    "\n",
    "### Matplotlib\n",
    "# Matplotlib is a Python based plotting library with complete 2D support and limited 3D support\n",
    "%matplotlib inline\n",
    "import matplotlib as mlb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Seaborn\n",
    "# Seaborn is a Python visualization library based on Matplolib, providing high-level interface for statistcial graphing\n",
    "# Seaborn supports numpy and pandas data structures as well as statistical routines from scipy and statsmodels\n",
    "# Note: https://seaborn.pydata.org/introduction.html\n",
    "import seaborn as sns\n",
    "\n",
    "### String\n",
    "# Allows for more flexible solutions for dealing with string characters\n",
    "import string as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                     Import Data                      ########\n",
    "######################################################################\n",
    "\n",
    "### Iris Data\n",
    "# load dataset from statsmodel modules\n",
    "iris = load_iris()\n",
    "\n",
    "### We need to add a dummy variable to indicate whether of not an affair occurred\n",
    "### 1 indicates having an affair, 0 represents not\n",
    "features = iris.feature_names\n",
    "print('Iris Feature Names in ndarry')\n",
    "print(features)\n",
    "\n",
    "######################################################################\n",
    "########                  Data Expoloration                   ########\n",
    "######################################################################\n",
    "\n",
    "### If iris was not a numpy ndarray we could rename the columns in the following manner\n",
    "# x = x.rename(columns = {'sepal length (cm)':'sepal_length',\n",
    "#                        'sepal width (cm)':'sepal_width',\n",
    "#                        'petal length (cm)':'petal_length',\n",
    "#                        'petal width (cm)':'petal_width'})\n",
    "\n",
    "### Since iris IS a numpy ndarry we must first make it a dataframe \n",
    "df = pd.DataFrame(data = iris.data, columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "y = pd.DataFrame(data = iris.target, columns = ['species'])\n",
    "\n",
    "### Let's determine how the data types look for this data frame\n",
    "print()\n",
    "print(\"Iris Feature Names in Data Frame\")\n",
    "for k in df.keys():\n",
    "    print(k)\n",
    "\n",
    "print()\n",
    "print(\"Are there any null values in our data frame?\")\n",
    "df.isnull().any()\n",
    "\n",
    "print()\n",
    "print(\"What are the data types of Iris' Features?\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print()\n",
    "print(\"Summary of Iris Data\")\n",
    "print(df.describe())\n",
    "\n",
    "### petal_width has a very large range between the maximum and minimum, let's view this\n",
    "df['petal_width'].plot.hist()\n",
    "plt.show()\n",
    "\n",
    "### Does not seem to be too odd given that it is probably a characteristic of the flower specied\n",
    "### We should proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                  Data Manipulation                   ########\n",
    "######################################################################\n",
    "\n",
    "### Species is currently an integer representation of the species, let's replace those values\n",
    "y = y.replace(0, 'setosa')\n",
    "y = y.replace(1, 'versicolor')\n",
    "y = y.replace(2, 'virginica')\n",
    "\n",
    "### We can join our independent and dependent variables together to make a complete data frame now\n",
    "iris = df.join(y)\n",
    "print(iris.head(3))\n",
    "print()\n",
    "######## How the Features Interact ######## \n",
    "sns.pairplot(iris, hue = 'species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                  Model Preparation                   ########\n",
    "######################################################################\n",
    "\n",
    "### Split the data set into dependent and independent variables\n",
    "x = iris.drop(['species'], axis = 1).values\n",
    "y = iris['species'].values\n",
    "\n",
    "### Split the data set into training and testing data sets; 70 - 30 split\n",
    "### you can use the argument 'random_state = BINARY' to decide if you want the test and train to be random or reproducable\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                     Modeling                         ########\n",
    "######################################################################\n",
    "\n",
    "### First we will create a Decision Tree object to use in our model\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "### Then we will train the Decision Tree model using our training data set\n",
    "dtc.fit(x_train, y_train)\n",
    "\n",
    "### Lastly, we will score the model using our testing data set\n",
    "print(\"Decision Tree Accuracy: \" + str((dtc.score(x_test, y_test) * 100).round(2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                  Model Validation                    ########\n",
    "######################################################################\n",
    "\n",
    "### The shuffle validator will apply the same 70-30 split as before, but generates 20 unique permutations of this split\n",
    "### By passing the shuffle validator as a parameter to the cross_val_score function we can score our classifer against each\n",
    "### of the different splits and compute their accuracy\n",
    "shuffle_validator = cross_validation.ShuffleSplit(len(x), n_iter = 20, test_size = 0.3, train_size = 0.7, random_state = 0)\n",
    "def test_classifier(clf):\n",
    "    scores = cross_validation.cross_val_score(clf, x, y, cv = shuffle_validator)\n",
    "    print(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "### Thus, no matter how we split the data we will recieve this % of correctly predicted survivals and the following \n",
    "### standard deviation \n",
    "test_classifier(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(DecisionTreeClassifier(), x, y, scoring = 'accuracy', cv = 10)\n",
    "print('Cross Validation Scores')\n",
    "print((scores * 100).round(0))\n",
    "print()\n",
    "print('Average Scores')\n",
    "print(str((scores.mean() * 100).round(0)) + '%')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
