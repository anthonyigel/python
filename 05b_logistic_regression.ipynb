{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "### Author: Anthony Igel                       ###\n",
    "### Team: Category Management Transformation   ###\n",
    "### Project: Developing practical Python Tools ###\n",
    "### Purpose: Logistic Regression               ###\n",
    "### Date: 05/24/2018                           ###\n",
    "##################################################\n",
    "\n",
    "######################################################################\n",
    "########                     Import Modules                   ########\n",
    "######################################################################\n",
    "import py_effo as py_effo\n",
    "\n",
    "### pandas\n",
    "# Pandas is for structured data operations and manipulations, extensively used for data preparation\n",
    "import pandas as pd\n",
    "\n",
    "### numpy\n",
    "# NumPy stands for Numerical Python, a library contains basic linear algebra functions, Fourier Transforms and advanced random\n",
    "# number capabilities\n",
    "import numpy as np \n",
    "\n",
    "### Scipy\n",
    "# Scipy performs a host of statistical calculations, built on top of Numpy, thus we do not need to import Numpy as all Numpy\n",
    "# functions are contained in Scipy\n",
    "# https://oneau.wordpress.com/2011/02/28/simple-statistics-with-scipy/\n",
    "import scipy as sp\n",
    "\n",
    "### sklearn\n",
    "# Sklearn contains basic statistical models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.model_selection  import cross_val_score\n",
    "# As well as a module to calculate model performance statistics\n",
    "from sklearn import metrics\n",
    "\n",
    "### Statsmodels\n",
    "# Sklearn contains basic statistical models and data sets\n",
    "import statsmodels.api as sm\n",
    "\n",
    "### Matplotlib\n",
    "# Matplotlib is a Python based plotting library with complete 2D support and limited 3D support\n",
    "%matplotlib inline\n",
    "import matplotlib as mlb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Seaborn\n",
    "# Seaborn is a Python visualization library based on Matplolib, providing high-level interface for statistcial graphing\n",
    "# Seaborn supports numpy and pandas data structures as well as statistical routines from scipy and statsmodels\n",
    "# Note: https://seaborn.pydata.org/introduction.html\n",
    "import seaborn as sns\n",
    "\n",
    "### String\n",
    "# Allows for more flexible solutions for dealing with string characters\n",
    "import string as st\n",
    "\n",
    "### Patsy.dmatrices\n",
    "# Python package for describing statistical models (especially linear models, or models that have a linear component) \n",
    "# and building design matrices\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                     Import Data                      ########\n",
    "######################################################################\n",
    "\n",
    "### Advertising Data\n",
    "# load dataset from statsmodel modules\n",
    "dta = sm.datasets.fair.load_pandas().data\n",
    "\n",
    "### We need to add a dummy variable to indicate whether of not an affair occurred\n",
    "### 1 indicates having an affair, 0 represents not\n",
    "dta['affair'] = (dta.affairs > 0).astype(int)\n",
    "\n",
    "######################################################################\n",
    "########                  Data Expoloration                   ########\n",
    "######################################################################\n",
    "### Identify any null values in data set\n",
    "print('Data Type Information of Affair Data')\n",
    "print(dta.info())\n",
    "print()\n",
    "print()\n",
    "### Identify any null values in data set\n",
    "print('Summary of Nulls in Affair Data')\n",
    "print(dta.isnull().sum())\n",
    "print()\n",
    "print()\n",
    "### Let's determine how the data types look for this data frame\n",
    "print('View Mean of Variables, Grouped by Affair Flag')\n",
    "print(dta.groupby('affair').mean())\n",
    "print()\n",
    "print()\n",
    "print('View Mean of Variables, Grouped by Rate_Marriage')\n",
    "print(dta.groupby('rate_marriage').mean())\n",
    "\n",
    "### From this, we can make a few assertions\n",
    "# 1. On average, women who have affairs rate their marriages lower\n",
    "# 2. An increase in age, yrs_married and children appear to correlate with a declining marriage rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                  Data Visualization                  ########\n",
    "######################################################################\n",
    "# show plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# histogram of education vs marriage rating\n",
    "dta.educ.hist()\n",
    "plt.title('Histogram of Education')\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "\n",
    "# histogram of marriage rating\n",
    "dta.rate_marriage.hist()\n",
    "plt.title('Histogram of Marriage Rating')\n",
    "plt.xlabel('Marriage Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "\n",
    "# barplot of marriage rating grouped by affair (True or False)\n",
    "pd.crosstab(dta.rate_marriage, dta.affair.astype(bool)).plot(kind='bar')\n",
    "plt.title('Marriage Rating Distribution by Affair Status')\n",
    "plt.xlabel('Marriage Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "\n",
    "# stacked barplot  of women having affairs by number of years of marriage\n",
    "affair_yrs_married = pd.crosstab(dta.yrs_married, dta.affair.astype(bool))\n",
    "affair_yrs_married.div(affair_yrs_married.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Affair Percentage by Years Married')\n",
    "plt.xlabel('Years Married')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                  Data Preparation                    ########\n",
    "######################################################################\n",
    "\n",
    "### This will ensure that all column names are stripped of whitespace\n",
    "dta.rename(columns = lambda x: x.strip(), inplace = True)\n",
    "\n",
    "### We can also adjust the case of our metrics table columns\n",
    "dta.rename(columns = lambda x: x.lower(), inplace = True)\n",
    "\n",
    "### We will want to add an intercept column as well as dummy variables for occupation and occupation_husb, since they are \n",
    "### categorical variables\n",
    "\n",
    "### The dmatricies function from the patsy module will help create dataframes with an intercept column and dummy variables for\n",
    "# occupation and occupation_husb\n",
    "y, x = dmatrices('affair ~ rate_marriage + age + yrs_married + children + \\\n",
    "                  religious + educ + C(occupation) + C(occupation_husb)',\n",
    "                  dta, return_type = \"dataframe\")\n",
    "print(x.columns)\n",
    "\n",
    "### Fix column names for the dummy variables \n",
    "\n",
    "x = x.rename(columns = {'C(occupation)[T.2.0]':'occ_2',\n",
    "                        'C(occupation)[T.3.0]':'occ_3',\n",
    "                        'C(occupation)[T.4.0]':'occ_4',\n",
    "                        'C(occupation)[T.5.0]':'occ_5',\n",
    "                        'C(occupation)[T.6.0]':'occ_6',\n",
    "                        'C(occupation_husb)[T.2.0]':'occ_husb_2',\n",
    "                        'C(occupation_husb)[T.3.0]':'occ_husb_3',\n",
    "                        'C(occupation_husb)[T.4.0]':'occ_husb_4',\n",
    "                        'C(occupation_husb)[T.5.0]':'occ_husb_5',\n",
    "                        'C(occupation_husb)[T.6.0]':'occ_husb_6'})\n",
    "print()\n",
    "print(x.columns)\n",
    "### Additionally, we need to flatten our dependent variable into a 1-D arrary so scikit-learn will properly understand it\n",
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                     Modeling                         ########\n",
    "######################################################################\n",
    "\n",
    "######## Logistic Regression ########\n",
    "\n",
    "### Lets run a logistic regression on the entire data set and see if it accurate\n",
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model = LogisticRegression()\n",
    "model = model.fit(x, y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "ModelScore_1 = model.score(x, y)\n",
    "print('Model Score: ' + str((ModelScore_1 * 100).round(0)) + '%')\n",
    "print()\n",
    "# what percentage had affairs?\n",
    "PredMean_1 = y.mean()\n",
    "print('What % of respondents had an affair? '+ str((PredMean_1 * 100).round(0)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######## Data Splitting ########\n",
    "\n",
    "### We want to split our independent and dependent data sets into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "print('Dependent Variables')\n",
    "print('Training: ' + str(len(x_train)))\n",
    "print('Testing: ' + str(len(x_test)))\n",
    "print()\n",
    "print('Independent Variables')\n",
    "print('Training: ' + str(len(y_train)))\n",
    "print('Testing: ' + str(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                     Modeling                         ########\n",
    "######################################################################\n",
    "\n",
    "######## Logistic Regression ########\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(x_train, y_train)\n",
    "\n",
    "### Predict class labels for the test set\n",
    "predicted = model2.predict(x_test)\n",
    "\n",
    "print('Predicted Values')\n",
    "print(predicted)\n",
    "print()\n",
    "### Generate class probabilities\n",
    "probs = model2.predict_proba(x_test)\n",
    "print('Prediction Probabilities')\n",
    "print(probs)\n",
    "print()\n",
    "\n",
    "### Generate evaluation metrics by using our predicted values compared to the truth\n",
    "AccuracyScore_2 = metrics.accuracy_score(y_test, predicted)\n",
    "RocAucScore_2 = metrics.roc_auc_score(y_test, probs[:, 1])\n",
    "print('Accuracy Score: ' + str((AccuracyScore_2 * 100).round(0)) + '%')\n",
    "print('ROC AUC Score: ' + str((RocAucScore_2 * 100).round(0)) + '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######## Additional Reports ########\n",
    "### Confusion Matrix\n",
    "## A confusion matrix is a summary of prediction results on a classification problem\n",
    "## The number of correct and incorrect predictions are summarised with count values\n",
    "\n",
    "## true prediction | false prediction\n",
    "## false prediction | true prediction\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "print()\n",
    "### Classification Report\n",
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                  Model Validation                    ########\n",
    "######################################################################\n",
    "\n",
    "### Evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), x, y, scoring = 'accuracy', cv = 10)\n",
    "print('Cross Validation Scores')\n",
    "print((scores * 100).round(0))\n",
    "print()\n",
    "print('Average Scores')\n",
    "print((scores.mean() * 100).round(0))\n",
    "\n",
    "### Model is still performing at 72% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "########                    Next Steps                        ########\n",
    "######################################################################\n",
    "\n",
    "### There are many different steps that could be tried in order to improve the model:\n",
    "# including interaction terms\n",
    "# removing features\n",
    "# regularization techniques\n",
    "# using a non-linear model"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
